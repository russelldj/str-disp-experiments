{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "\n",
    "# Contributed library imports\n",
    "import numpy as np\n",
    "\n",
    "# Our imports\n",
    "from multiview_mapping_toolkit.cameras.derived_cameras import MetashapeCameraSet\n",
    "from multiview_mapping_toolkit.meshes import TexturedPhotogrammetryMesh\n",
    "from multiview_mapping_toolkit.segmentation import (\n",
    "    LookUpSegmentor,\n",
    "    SegmentorPhotogrammetryCameraSet,\n",
    ")\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from constants import (\n",
    "    get_mesh_filename,\n",
    "    get_camera_filename,\n",
    "    get_predicted_vector_labels_filename,\n",
    "    get_numpy_export_faces_texture_filename,\n",
    "    get_oblique_images_folder,\n",
    "    get_DTM_filename,\n",
    "    get_prediction_folder,\n",
    "    get_image_folder,\n",
    "    get_IDs_to_labels,\n",
    "    get_mesh_transform_filename,\n",
    "    LABELS_FILENAME,\n",
    "    BUFFER_RADIUS_METERS,\n",
    "    AGGREGATE_IMAGE_SCALE,\n",
    "    HEIGHT_ABOVE_GROUND_THRESH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set constants\n",
    "You should be able to define most of the behavior from these constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SITES = sorted([\"none\", \"none\", \"none\"])\n",
    "PREDICTION_SITE_NAME = \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESH_FILENAME = get_mesh_filename(PREDICTION_SITE_NAME)\n",
    "CAMERAS_FILENAME = get_camera_filename(PREDICTION_SITE_NAME)\n",
    "IDs_TO_LABELS = get_IDs_to_labels()\n",
    "TRANSFORM_FILENAME = get_mesh_transform_filename(PREDICTION_SITE_NAME)\n",
    "\n",
    "mesh = TexturedPhotogrammetryMesh(\n",
    "    MESH_FILENAME,\n",
    "    transform_filename=TRANSFORM_FILENAME,\n",
    "    ROI=LABELS_FILENAME,\n",
    "    ROI_buffer_meters=BUFFER_RADIUS_METERS,\n",
    "    IDs_to_labels=IDs_TO_LABELS,\n",
    ")\n",
    "print(\"Done creating mesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = get_image_folder(PREDICTION_SITE_NAME)\n",
    "OBLIQUE_IMAGES_FOLDER = get_oblique_images_folder(PREDICTION_SITE_NAME)\n",
    "\n",
    "# Create camera set\n",
    "print(CAMERAS_FILENAME)\n",
    "camera_set = MetashapeCameraSet(CAMERAS_FILENAME, IMAGE_FOLDER)\n",
    "# Extract cameras near the training data\n",
    "training_camera_set = camera_set.get_subset_ROI(\n",
    "    ROI=LABELS_FILENAME, buffer_radius_meters=BUFFER_RADIUS_METERS\n",
    ")\n",
    "training_camera_set = training_camera_set.get_cameras_in_folder(OBLIQUE_IMAGES_FOLDER)\n",
    "print(\"About to vis\")\n",
    "# %%\n",
    "mesh.vis(camera_set=training_camera_set, force_xvfb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_FOLDER = get_prediction_folder(\n",
    "    prediction_site=PREDICTION_SITE_NAME, training_sites=TRAINING_SITES, is_ortho=False\n",
    ")\n",
    "# %%\n",
    "segmentor = LookUpSegmentor(\n",
    "    base_folder=IMAGE_FOLDER,\n",
    "    lookup_folder=PREDICTIONS_FOLDER,\n",
    "    num_classes=8,\n",
    ")\n",
    "\n",
    "segmentor_camera_set = SegmentorPhotogrammetryCameraSet(\n",
    "    training_camera_set, segmentor=segmentor\n",
    ")\n",
    "\n",
    "aggregated_face_labels, _, _ = mesh.aggregate_viewpoints_pytorch3d(\n",
    "    segmentor_camera_set,\n",
    "    image_scale=AGGREGATE_IMAGE_SCALE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTM_FILE = get_DTM_filename(PREDICTION_SITE_NAME)\n",
    "NUMPY_EXPORT_FACES_TEXTURE_FILE = get_numpy_export_faces_texture_filename(PREDICTION_SITE_NAME, training_sites=TRAINING_SITES)\n",
    "PREDICTED_VECTOR_LABELS_FILE = get_predicted_vector_labels_filename(PREDICTION_SITE_NAME, training_sites=TRAINING_SITES)\n",
    "\n",
    "# Save out the aggregated labels\n",
    "NUMPY_EXPORT_FACES_TEXTURE_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "np.save(NUMPY_EXPORT_FACES_TEXTURE_FILE, aggregated_face_labels)\n",
    "\n",
    "# Compute the most commonly predicted face\n",
    "predicted_face_classes = np.argmax(\n",
    "    aggregated_face_labels, axis=1, keepdims=True\n",
    ").astype(float)\n",
    "predicted_face_classes = mesh.label_ground_class(\n",
    "    labels=predicted_face_classes,\n",
    "    height_above_ground_threshold=HEIGHT_ABOVE_GROUND_THRESH,\n",
    "    DTM_file=DTM_FILE,\n",
    "    ground_ID=np.nan,\n",
    "    set_mesh_texture=False,\n",
    ")\n",
    "\n",
    "# Visualize the max prediction\n",
    "mesh.vis(\n",
    "    vis_scalars=predicted_face_classes,\n",
    "    force_xvfb=True,\n",
    ")\n",
    "# Export the geospatial labeling\n",
    "mesh.export_face_labels_vector(\n",
    "    face_labels=np.squeeze(predicted_face_classes),\n",
    "    export_file=PREDICTED_VECTOR_LABELS_FILE,\n",
    "    vis=True,\n",
    "    vis_kwargs={\"cmap\": \"tab10\", \"vmin\": -0.5, \"vmax\": 9.5},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
