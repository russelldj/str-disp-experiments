{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Contributed imports\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "# Our imports\n",
    "from multiview_mapping_toolkit.cameras.derived_cameras import MetashapeCameraSet\n",
    "from multiview_mapping_toolkit.meshes import TexturedPhotogrammetryMesh\n",
    "from multiview_mapping_toolkit.utils.visualization import show_segmentation_labels\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from constants import (\n",
    "    LABELS_COLUMN,\n",
    "    LABELS_FILENAME,\n",
    "    HEIGHT_ABOVE_GROUND_THRESH,\n",
    "    RENDER_IMAGE_SCALE,\n",
    "    BUFFER_RADIUS_METERS,\n",
    "    DOWNSAMPLE_TARGET,\n",
    "    get_labeled_mesh_filename,\n",
    "    get_mesh_filename,\n",
    "    get_camera_filename,\n",
    "    get_DTM_filename,\n",
    "    get_image_folder,\n",
    "    get_oblique_images_folder,\n",
    "    get_images_near_labels_folder,\n",
    "    get_render_scratch_folder,\n",
    "    get_render_folder,\n",
    "    get_IDs_to_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set constants\n",
    "You should be able to define most of the behavior from these constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set this to the site you want\n",
    "# TODO change this constant name\n",
    "SHORT_MODEL_NAME = \"valley\"\n",
    "# Repeat the mesh labeling process\n",
    "RETEXTURE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial processing\n",
    "\n",
    "Preprocess the geospatial data to be as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "gdf = gpd.read_file(LABELS_FILENAME)\n",
    "\n",
    "gdf.query(\"fire==@SHORT_MODEL_NAME\").plot(LABELS_COLUMN, legend=True, vmin=-0.5, vmax=9.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a set of cameras and downsample them to the region around annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = get_image_folder(SHORT_MODEL_NAME)\n",
    "IMAGE_FOLDER_OBLIQUE = get_oblique_images_folder(SHORT_MODEL_NAME)\n",
    "CAMERAS_FILENAME = get_camera_filename(SHORT_MODEL_NAME)\n",
    "\n",
    "# Create camera set\n",
    "camera_set = MetashapeCameraSet(CAMERAS_FILENAME, IMAGE_FOLDER)\n",
    "# Extract cameras near the training data\n",
    "training_camera_set = camera_set.get_subset_ROI(\n",
    "    ROI=LABELS_FILENAME, buffer_radius_meters=BUFFER_RADIUS_METERS\n",
    ")\n",
    "training_camera_set = training_camera_set.get_cameras_in_folder(IMAGE_FOLDER_OBLIQUE)\n",
    "training_camera_set.vis(force_xvfb=True, frustum_scale=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the mesh and read texture from geopolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MESH_FILENAME = get_mesh_filename(SHORT_MODEL_NAME)\n",
    "LABELED_MESH_FILENAME = get_labeled_mesh_filename(SHORT_MODEL_NAME)\n",
    "DTM_FILENAME = get_DTM_filename(SHORT_MODEL_NAME)\n",
    "IDS_TO_LABELS = get_IDs_to_labels()\n",
    "\n",
    "\n",
    "# Create a labeled version of the mesh from the field data\n",
    "# if not present or requested\n",
    "if not Path(LABELED_MESH_FILENAME).is_file() or RETEXTURE:\n",
    "    # Load the downsampled mesh and apply the texture from the vector file\n",
    "    mesh = TexturedPhotogrammetryMesh(\n",
    "        MESH_FILENAME,\n",
    "        downsample_target=DOWNSAMPLE_TARGET,\n",
    "        ROI=LABELS_FILENAME,\n",
    "        ROI_buffer_meters=BUFFER_RADIUS_METERS,\n",
    "        texture=LABELS_FILENAME,\n",
    "        texture_column_name=LABELS_COLUMN,\n",
    "        transform_filename=CAMERAS_FILENAME,\n",
    "        IDs_to_labels=IDS_TO_LABELS,\n",
    "    )\n",
    "    # Label the ground class\n",
    "    mesh.label_ground_class(\n",
    "        DTM_file=DTM_FILENAME,\n",
    "        height_above_ground_threshold=HEIGHT_ABOVE_GROUND_THRESH,\n",
    "        only_label_existing_labels=True,\n",
    "        ground_class_name=\"ground\",\n",
    "        ground_ID=np.nan,\n",
    "        set_mesh_texture=True,\n",
    "    )\n",
    "\n",
    "    mesh.save_mesh(LABELED_MESH_FILENAME, save_vert_texture=True)\n",
    "else:\n",
    "    mesh = TexturedPhotogrammetryMesh(\n",
    "        LABELED_MESH_FILENAME, transform_filename=CAMERAS_FILENAME\n",
    "    )\n",
    "print(f\"IDs to labels: {mesh.IDs_to_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can include the camera set, but it's cleaner without it\n",
    "mesh.vis(camera_set=None, force_xvfb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render the labels onto the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RENDER_FOLDER_SCRATCH = get_render_scratch_folder(SHORT_MODEL_NAME)\n",
    "\n",
    "mesh.save_renders_pytorch3d(\n",
    "    camera_set=training_camera_set,\n",
    "    render_image_scale=RENDER_IMAGE_SCALE,\n",
    "    save_native_resolution=True,\n",
    "    output_folder=RENDER_FOLDER_SCRATCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save out the subset of images near the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_NEAR_LABELS_FOLDER = get_images_near_labels_folder(SHORT_MODEL_NAME)\n",
    "\n",
    "if not IMAGES_NEAR_LABELS_FOLDER.is_dir():\n",
    "    print(f\"Saving subset of images near labels to {IMAGES_NEAR_LABELS_FOLDER}\")\n",
    "    training_camera_set.save_images(IMAGES_NEAR_LABELS_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show some of the rendered labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_segmentation_labels(label_folder=RENDER_FOLDER_SCRATCH, image_folder=IMAGE_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move files from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RENDER_FOLDER = get_render_folder(SHORT_MODEL_NAME)\n",
    "shutil.move(src=RENDER_FOLDER_SCRATCH, dst=RENDER_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MVMT-stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
